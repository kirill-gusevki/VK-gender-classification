# VK-gender-classification
Датасеты можно найти на сайте - https://cups.online/ru/tasks/1923, (загрузка невозможно из-за большого веса файлов)

Описание проекта
Проект был выполнен в рамках задания от компании VK. Цель — разработать модель машинного обучения, которая предсказывает пол пользователя.

Задача: Бинарная классификация (пол пользователя: 1 / 0).

Ключевые навыки, продемонстрированные в проекте
Обработка больших данных: Работа с объёмными табличными данными (более 500k пользователей).

Feature Engineering: Создание новых признаков из сырых данных: парсинг User Agent, работа с временными рядами, извлечение признаков из URL, обработка геоданных.

Работа с различными источниками данных: Горизонтальное объединение данных из 5 разных источников (train.csv, geo_info.csv, referer_vectors.csv и т.д.).

Агрегация данных: Преобразование данных на уровне событий (просмотров) в данные на уровне пользователя.

Машинное обучение: Построение и обучение модели градиентного бустинга (LightGBM) с настройкой гиперпараметров и кросс-валидацией.

Валидация и оценка качества: Оценка модели с помощью метрики AUC-ROC. Результат на валидационной выборке: 0.8904.

Инструменты: Python, Pandas, NumPy, Scikit-learn, LightGBM.

Структура репозитория
text
VK-Gender-Prediction/
├── data/                    # Исходные данные (не включены в репозиторий)
├── notebooks/
│   └── VK.ipynb  # Полный Jupyter Notebook с кодом
├── models/
│   ├── gender_prediction_model.joblib    # Обученная модель
│   └── feature_names.json                # Список признаков для модели
├── results/
│   └── gender_prediction_submission.csv  # Предсказания для тестовой выборки
└── README.md
Данные
В распоряжении были следующие данные:

train_labels.csv: user_id и целевая переменная target (пол).

train.csv / test.csv: События пользователей с временными метками, URL объявлений, гео-данными и User Agent.

referer_vectors.csv: Векторные представления URL объявлений (10 компонент).

geo_info.csv: Справочник с информацией о геолокациях.

test_users.csv: Список пользователей, для которых нужно было сделать прогноз.

Основные этапы решения
Первичная обработка и анализ данных:

Загрузка и проверка согласованности всех таблиц.

Парсинг JSON-подобного поля user_agent и извлечение признаков (browser, OS, version).

Feature Engineering:

Временные признаки: Извлечение часа, дня недели, времени суток (ночь/утро/день/вечер) из timestamp.

Признаки из User Agent: Создание бинарных признаков для популярных браузеров (Chrome, Safari, etc.), выделение мобильных OS (iOS/Android).

Признаки из URL: Разбиение referer на домен и путь, вычисление "сложности" пути.

Гео-признаки: Обогащение данными о стране, регионе и часовом поясе.

Агрегация и подготовка данных к моделированию:

Агрегация всех событий по user_id (средние значения, мода, стандартное отклонение и др.).

Согласованное кодирование категориальных признаков на объединённой выборке (train + test).

Заполнение пропущенных значений.

Построение и обучение модели:

Для решения задачи был выбран градиентный бустинг (LightGBM) как один из лучших алгоритмов для табличных данных.

Модель обучалась с использованием ранней остановки (early stopping) для предотвращения переобучения.

Результат: Качество модели оценено по метрике AUC-ROC = 0.8904.

Важность признаков:

Наибольший вклад в прогноз внесли векторные представления URL (component2_mean, component3_mean), средний час активности пользователя (avg_hour) и категориальные признаки (основной браузер и страна).
